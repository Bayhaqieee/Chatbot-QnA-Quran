{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1E9BRkr3hBx8yPEZ336cDlK3bxN1RCJGa",
      "authorship_tag": "ABX9TyM777SO3W3VEaBzFUPnOC3O"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Q&A Quranic Reasoning"
      ],
      "metadata": {
        "id": "B-QR-Fuey5Wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Understanding"
      ],
      "metadata": {
        "id": "69bv8XSgy6Vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bagaimana potensi penggunaan QRQA Dataset dalam mengembangkan produk edukasi digital Islam berbasis AI (seperti chatbot tanya jawab, aplikasi pembelajaran, atau virtual mufti)?\n",
        "\n",
        "  _Untuk mengidentifikasi peluang produk turunan dan segmen pasar potensial (pelajar, akademisi, pesantren digital, dll.)._\n",
        "\n",
        "- Model bahasa mana (seperti LLaMA, Mistral, DeepSeek, dsb.) yang paling cocok untuk fine-tuning dengan QRQA Dataset dalam konteks kecepatan, akurasi, dan efisiensi biaya?\n",
        "\n",
        "  _Akan dites pada Notebook ini._\n",
        "\n",
        "- Bagaimana cara mengukur efektivitas reasoning model terhadap pertanyaan-pertanyaan kompleks dalam QRQA?\n",
        "\n",
        "  _Menggunakan metrik evaluasi seperti BLEU, ROUGE, atau human-evaluated Islamic consistency score._"
      ],
      "metadata": {
        "id": "nQvFsf1zzChe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data and Tools Acquisition"
      ],
      "metadata": {
        "id": "0i30LmD2zM3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install kaggle\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "0TFI_aqey8sC",
        "outputId": "1ae695c9-df52-4db6-a813-6ef312ec54f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-ff90bc3ec37f>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ff90bc3ec37f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    - Bagaimana potensi penggunaan QRQA Dataset dalam mengembangkan produk edukasi digital Islam berbasis AI (seperti chatbot tanya jawab, aplikasi pembelajaran, atau virtual mufti)?\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHSOEfmcyo4-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "from google.colab import files\n",
        "import os\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "eInX82SgzRBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/CollabData/kaggle_API/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "T7bC_IjTAuVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "flupYIErA0Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download lazer999/quranic-reasoning-synthetic-dataset"
      ],
      "metadata": {
        "id": "rEPMz_J9A0hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download alizahidraja/quran-english"
      ],
      "metadata": {
        "id": "5dk2P-gDA3VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip quranic-reasoning-synthetic-dataset.zip"
      ],
      "metadata": {
        "id": "OjUkNhzaA4mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip quran-english.zip"
      ],
      "metadata": {
        "id": "9A_cbtuEA6U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "V0ExrsVSAzk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Quran_R1_excel.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rbgh4ZudA-p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "mKPzx0BkBFaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column `Unnamed: 0` merupakan Column yang harus kita drop karena tidak berguna"
      ],
      "metadata": {
        "id": "r4D18cypBJS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "id": "i3TaQ63ABKqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go to the next data"
      ],
      "metadata": {
        "id": "KnmWuXsdDIfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Quran_English_with_Tafseer.csv\"\n",
        "df_quran = pd.read_csv(file_path)\n",
        "df_quran.head()"
      ],
      "metadata": {
        "id": "cSjUyjt4DEAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_quran.info()"
      ],
      "metadata": {
        "id": "GQFLWwrKDHsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_quran[df_quran['Tafseer'].isnull()])"
      ],
      "metadata": {
        "id": "uevAeSUzDNAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ada satu data yang tidak memiliki tafsir kosong, dalam hal ini kita akan isi data kosong ini dengan data sintetis"
      ],
      "metadata": {
        "id": "C54qhQS2DUN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill empty 'Tafseer' values with a synthetic data\n",
        "df_quran['Tafseer'] = df_quran['Tafseer'].fillna(\"This surah emphasizes that Allah is the protector and ally (Mawlā) of those who believe, offering them divine support, guidance, and victory, while the disbelievers are left without any true protector. This verse reassures the believers that despite external challenges or opposition, they are never alone—Allah stands by them in both worldly and spiritual affairs. Conversely, disbelievers, no matter their apparent power or alliances, lack divine backing and are ultimately vulnerable. Revealed in the context of struggle between faith and disbelief, particularly in times of conflict, this verse highlights the importance of trusting in Allah, as real strength and success come through His support, not mere worldly means.\")\n",
        "print(df_quran[df_quran['Tafseer'].isnull()])"
      ],
      "metadata": {
        "id": "MJrF2jNzDUvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Merging"
      ],
      "metadata": {
        "id": "ca4WS2ykDdSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum kita develop modelnya, mari kita gabung `df_quran` dengan `df`"
      ],
      "metadata": {
        "id": "NOMdJY8qDf0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the first template\n",
        "df_quran['Question'] = \"Question: What is the meaning of Surah \" + df_quran['Surah'].astype(str) + \":\" + df_quran['Ayat'].astype(str) + \"?\"\n",
        "df_quran['Response'] = \"Response: \\nVerse:\\n\" + df_quran['Verse'] + \", \" + df_quran['Tafseer']\n",
        "\n",
        "# Create the second template and append it to the first dataframe\n",
        "df_quran_2 = pd.DataFrame()\n",
        "df_quran_2['Question'] = \"Question: What is the meaning of Surah \" + df_quran['Name'] + \":\" + df_quran['Ayat'].astype(str) + \"?\"\n",
        "df_quran_2['Response'] = \"Response: \\nVerse:\\n\" + df_quran['Verse'] + \", \" + df_quran['Tafseer']\n",
        "\n",
        "df_quran = pd.concat([df_quran, df_quran_2], ignore_index=True)\n",
        "\n",
        "# Select only the relevant columns for merging\n",
        "df_quran = df_quran[['Question', 'Response']]\n",
        "\n",
        "# Concatenate the two dataframes\n",
        "merged_df = pd.concat([df, df_quran], ignore_index=True)\n",
        "merged_df.head()\n"
      ],
      "metadata": {
        "id": "D3UxmNq7Deq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Development\n",
        "\n",
        "Kita akan menggunakan model T5, cek penjelasan Transformer [disini](https://medium.com/@gagangupta_82781/understanding-the-t5-model-a-comprehensive-guide-b4d5c02c234b)"
      ],
      "metadata": {
        "id": "5EoP4LahNCp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputt=merged_df['Question'].tolist()\n",
        "labelt=merged_df['Response'].tolist()"
      ],
      "metadata": {
        "id": "qbq9tkIjNEJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Train-Test (Dalam hal ini kita akan pisah 9:1, dan kita hanya akan mengambil data dari `df` saja)"
      ],
      "metadata": {
        "id": "rz92pm-xNcRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputt[:857], labelt[:857], test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "WcaPGE3ANYMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mari kita Panggil Tokenizer dan Pre-Model yang akan kita pakai, dalam hal ini T5"
      ],
      "metadata": {
        "id": "lteGKYh4OBN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "id": "ARjHP3O3OGzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum melatih model, mari kita tokenisasi data"
      ],
      "metadata": {
        "id": "lOe6a3hbVjo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(inputs, labels, tokenizer, max_length=128):\n",
        "    input_encodings = tokenizer(\n",
        "        list(inputs), max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    label_encodings = tokenizer(\n",
        "        list(labels), max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    return input_encodings, label_encodings\n",
        "\n",
        "train_inputs_enc, train_labels_enc = tokenize_data(train_inputs, train_labels, tokenizer)\n",
        "test_inputs_enc, test_labels_enc = tokenize_data(test_inputs, test_labels, tokenizer)"
      ],
      "metadata": {
        "id": "dQt9c-r0Vj-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
        "            \"labels\": self.labels[\"input_ids\"][idx],\n",
        "        }\n",
        "\n",
        "train_dataset = CustomDataset(train_inputs_enc, train_labels_enc)\n",
        "test_dataset = CustomDataset(test_inputs_enc, test_labels_enc)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)"
      ],
      "metadata": {
        "id": "Mrp_MsIYV5Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mari kita train model kita kali ini serta menggunakan Optimizer untuk meningkatkan Akurasi model!"
      ],
      "metadata": {
        "id": "GJIoQQ66V8GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "epochs = 300\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "TBmP_oy6V54_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch terakhir menunjukkan 0.13 Loss"
      ],
      "metadata": {
        "id": "vDTXB3p0Xk8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "cqG58F5DXoaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "for batch in test_loader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_mask\"].to(device)\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "\n",
        "    input_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in input_ids]\n",
        "    true_labels = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=50\n",
        "    )\n",
        "    predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "\n",
        "    for input_text, true_label, pred in zip(input_texts, true_labels, predictions):\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"input_txt: {input_text}\")\n",
        "        print(f\"true_label: {true_label}\")\n",
        "        print(f\"true_pred: {pred}\")\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "rLZrP44tXllW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "PzMCtm-vXs0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Assuming 'predictions' and 'true_labels' are lists of strings from the previous code block\n",
        "\n",
        "bleu_scores = []\n",
        "rouge1_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "for prediction, true_label in zip(predictions, true_labels):\n",
        "  # Calculate BLEU score\n",
        "  reference = [true_label.split()]\n",
        "  candidate = prediction.split()\n",
        "  bleu_score = sentence_bleu(reference, candidate)\n",
        "  bleu_scores.append(bleu_score)\n",
        "\n",
        "  # Calculate ROUGE scores\n",
        "  scores = scorer.score(true_label, prediction)\n",
        "  rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "  rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average scores\n",
        "avg_bleu = np.mean(bleu_scores)\n",
        "avg_rouge1 = np.mean(rouge1_scores)\n",
        "avg_rougeL = np.mean(rougeL_scores)\n",
        "\n",
        "print(f\"Average BLEU Score: {avg_bleu}\")\n",
        "print(f\"Average ROUGE-1 Score: {avg_rouge1}\")\n",
        "print(f\"Average ROUGE-L Score: {avg_rougeL}\")\n"
      ],
      "metadata": {
        "id": "ogvbZYPsXwfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Penjelasan Setiap Metrik\n",
        "\n",
        "---\n",
        "\n",
        "- **BLEU (Bilingual Evaluation Understudy)**\n",
        "\n",
        "  > Nilai: 0.050\n",
        "\n",
        "  BLEU digunakan untuk mengukur kemiripan antara hasil generasi model dengan jawaban referensi berdasarkan kesamaan n-gram.\n",
        "\n",
        "  Skor BLEU < 0.1 dalam konteks QnA bersifat umum, terutama pada teks yang bersifat panjang, reasoning, atau bernuansa keagamaan karena struktur jawabannya bisa sangat variatif tergantung pertanyaannya.\n",
        "\n",
        "  Dalam model kali ini, skor BLEU kita relatif **Rendah** yang dimana menunjukkan bahwa model menghasilkan jawaban yang secara kata-kata sangat berbeda dari jawaban referensi, meskipun bisa saja maknanya benar.\n",
        "\n",
        "---\n",
        "\n",
        "- **ROUGE-1**\n",
        "  > Nilai: 0.405\n",
        "\n",
        "  Mengukur kesamaan kata secara langsung (unigram overlap) antara jawaban model dan jawaban referensi.\n",
        "\n",
        "  Skor di atas 0.4 dianggap **Cukup Baik** untuk tugas QnA generatif.\n",
        "\n",
        "---\n",
        "\n",
        "- **ROUGE-L**\n",
        "  > Nilai: 0.319\n",
        "\n",
        "  Mengukur kesamaan struktur atau urutan kata (longest common subsequence).\n",
        "\n",
        "  Skor di atas 0.3 menunjukkan bahwa model **Cukup Baik** dalam meniru sebagian struktur kalimat dari jawaban referensi."
      ],
      "metadata": {
        "id": "0wA6lLQzYCZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Saving"
      ],
      "metadata": {
        "id": "9JhwUHjmYNKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_path = \"/content/drive/MyDrive/CollabData/QuranicReasoningModel/Model1\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "id": "6ayA7q4pYInv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}